{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from rpy2.robjects.packages import importr # You may need to run \"pip install rpy2\" in Terminal\n",
    "import rpy2 as ro\n",
    "import pandas as pd\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         date Final_Pred\n",
       "1  2016-06-24    6320805\n",
       "2  2016-06-25    6319728\n",
       "3  2016-06-26    6319809\n",
       "4  2016-06-27    6320456\n",
       "5  2016-06-28    6320077\n",
       "6  2016-06-29    6319349\n",
       "7  2016-06-30    6319235\n",
       "8  2016-07-01    6317981\n",
       "9  2016-07-02    6318673\n",
       "10 2016-07-03    6320163\n",
       "11 2016-07-04    6320392\n",
       "12 2016-07-05    6320535\n",
       "13 2016-07-06    6319366\n",
       "14 2016-07-07    6319571\n",
       "15 2016-07-08    6320591\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R \n",
    "rm(list=ls())\n",
    "library('DBI')\n",
    "library('RPostgreSQL')\n",
    "drv <- dbDriver('PostgreSQL')\n",
    "con <- dbConnect(drv, \n",
    "                 host=\"#######################################\", \n",
    "                 port=\"#####\",\n",
    "                 dbname=\"####\", \n",
    "                 user=\"######", \n",
    "                 password=\"##################\")\n",
    "query_1 <- \"SELECT \n",
    "date,\n",
    "first_value(arr) OVER (partition by arr_partition) AS arr,\n",
    "COALESCE(churn, 0) AS churn,\n",
    "first_value(account_holders) OVER (partition by account_holders_partition) AS account_holders,\n",
    "first_value(arpu) OVER (partition by arpu_partition) AS arpu,\n",
    "first_value(renewal_account_customer) OVER (partition by renewal_account_partition) AS renewal_account_customers,\n",
    "(first_value(renewal_account_customer) OVER (partition by renewal_account_partition)*(1.0))/\n",
    "first_value(account_holders) OVER (partition by account_holders_partition) AS percentage_onboarded\n",
    "FROM\n",
    "(               \n",
    "SELECT \n",
    "a.date,\n",
    "arr,\n",
    "churn,\n",
    "account_holders,\n",
    "arpu,\n",
    "renewal_account_customer,\n",
    "SUM(CASE WHEN arr IS NULL THEN 0 ELSE 1 END) \n",
    "OVER (ORDER BY a.date ROWS BETWEEN unbounded preceding AND 0 following) AS arr_partition,\n",
    "SUM(CASE WHEN account_holders IS NULL THEN 0 ELSE 1 END) \n",
    "OVER (ORDER BY a.date ROWS BETWEEN unbounded preceding AND 0 following) AS account_holders_partition,\n",
    "SUM(CASE WHEN arpu IS NULL THEN 0 ELSE 1 END) \n",
    "OVER (ORDER BY a.date ROWS BETWEEN unbounded preceding AND 0 following) AS arpu_partition,\n",
    "SUM(CASE WHEN renewal_account_customer IS NULL THEN 0 ELSE 1 END) \n",
    "OVER (ORDER BY a.date ROWS BETWEEN unbounded preceding AND 0 following) AS renewal_account_partition\n",
    "FROM\n",
    "(         \n",
    "SELECT *\n",
    "FROM\n",
    "(\n",
    "  SELECT \n",
    "  DATE(dateadd(day,730,(getdate()::date - row_number() over (order by true))::date)) as date\n",
    "  FROM data_warehouse.activity_account \n",
    ")\n",
    "WHERE date >= '2015-07-01'\n",
    "AND date < CURRENT_DATE\n",
    "ORDER BY date\n",
    ") a\n",
    "LEFT JOIN\n",
    "(\n",
    "  SELECT \n",
    "  date, \n",
    "  arr,\n",
    "  CASE WHEN churn = first_churn THEN churn ELSE churn - LAG(churn) OVER (ORDER BY date) END AS churn,\n",
    "  account_holders,\n",
    "  arpu,\n",
    "  renewal_account_customer\n",
    "  FROM\n",
    "  (\n",
    "  SELECT  \n",
    "  log_ymd as date, \n",
    "  arr,\n",
    "  churn_account * (-1) AS churn,\n",
    "  (first_value(churn_account) OVER (partition by to_char(log_ymd, 'YYYY-MM'))) * (-1) AS first_churn,\n",
    "  new_account_including_future  \n",
    "  + renewal_account_customer + new_account_onboarding + new_account_customer AS account_holders,\n",
    "  (arr/12)/(new_account_including_future \n",
    "  + renewal_account_customer + new_account_onboarding + new_account_customer) AS arpu, \n",
    "  renewal_account_customer          \n",
    "  FROM data_warehouse.account_financial_mrr_log\n",
    "  WHERE EXTRACT(month FROM cohort_year_month_date) = EXTRACT(month FROM log_ymd)\n",
    "  AND cohort_year_month_date <= DATE(convert_timezone('GMT','US/Pacific',CURRENT_DATE))\n",
    "  AND to_char(log_ymd, 'YYYY-MM') = cohort_year_month \n",
    "  AND cohort_type = 'all'\n",
    "  AND deleted_at IS NULL\n",
    "  )\n",
    ") b\n",
    "  ON a.date = b.date\n",
    ")\n",
    "ORDER BY date\"\n",
    "\n",
    "res_1 <- dbSendQuery(con, query_1, timeout = 600)\n",
    "df  <- as.data.frame(dbFetch(res_1)); dbClearResult(res_1)\n",
    "df$dod_churn_rate <- (df$churn)/(df$arr)\n",
    "library(lubridate)\n",
    "df$months <- paste(year(df$date), '-', month(df$date),sep='')\n",
    "\n",
    "# Add booleans for day of week\n",
    "\n",
    "df$day <- weekdays(as.Date(df$date))\n",
    "df$Monday <- ifelse(df$day == \"Monday\", 1, 0)\n",
    "df$Tuesday <- ifelse(df$day == \"Tuesday\", 1, 0)\n",
    "df$Wednesday <- ifelse(df$day == \"Wednesday\", 1, 0)\n",
    "df$Thursday <- ifelse(df$day == \"Thursday\", 1, 0)\n",
    "df$Friday <- ifelse(df$day == \"Friday\", 1, 0)\n",
    "df$Saturday <- ifelse(df$day == \"Saturday\", 1, 0)\n",
    "df$Sunday <- ifelse(df$day == \"Sunday\", 1, 0)\n",
    "df$Weekend <- ifelse(df$day == \"Sunday\" | df$day == \"Saturday\", 1, 0)\n",
    "\n",
    "# Add booleans for month\n",
    "\n",
    "df$January <- ifelse(df$month == '1', 1, 0)\n",
    "df$February <- ifelse(df$month == '2', 1, 0)\n",
    "df$March <- ifelse(df$month == '3', 1, 0)\n",
    "df$April <- ifelse(df$month == '4', 1, 0)\n",
    "df$May <- ifelse(df$month == '5', 1, 0)\n",
    "df$June <- ifelse(df$month == '6', 1, 0)\n",
    "df$July <- ifelse(df$month == '7', 1, 0)\n",
    "df$August <- ifelse(df$month == '8', 1, 0)\n",
    "df$September <- ifelse(df$month == '9', 1, 0)\n",
    "df$October <- ifelse(df$month == '10', 1, 0)\n",
    "df$November <- ifelse(df$month == '11', 1, 0)\n",
    "df$December <- ifelse(df$month == '12', 1, 0)\n",
    "\n",
    "# Add pricing data\n",
    "setwd(\"/Users/bsknight/Documents/June 2016 Forecasting Project\")\n",
    "# .csv generated from https://stitchlabs.looker.com/x/8pW9pqs\n",
    "pricing_plans <- read.csv(\"Pricing_Plans.csv\")\n",
    "library(kimisc)\n",
    "pricing_plans$over_300 <- (\n",
    "  coalesce.na(pricing_plans$plan.3.60.State2.Count.Accounts, 0)  \n",
    "  + coalesce.na(pricing_plans$plan.5.60.State2.Count.Accounts, 0)\n",
    "  + coalesce.na(pricing_plans$plan.6.40.State2.Count.Accounts, 0)\n",
    "  + coalesce.na(pricing_plans$plan.6.90.State2.Count.Accounts, 0)\n",
    "  + coalesce.na(pricing_plans$plan.6.41.State2.Count.Accounts, 0)\n",
    "  + coalesce.na(pricing_plans$plan.6.91.State2.Count.Accounts, 0)\n",
    "  + coalesce.na(pricing_plans$plan.7.30.State2.Count.Accounts, 0)\n",
    "  + coalesce.na(pricing_plans$plan.7.31.State2.Count.Accounts, 0)\n",
    "  + coalesce.na(pricing_plans$plan.7.32.State2.Count.Accounts, 0)\n",
    ")/pricing_plans$State2.Count.Accounts\n",
    "pricing_plans$date <- as.Date(pricing_plans$Account.Date.Account.Date.Date)\n",
    "pricing_plans <- pricing_plans[, 38:39]\n",
    "df <- merge(x = df, y = pricing_plans, by.x = \"date\",  by.y = \"date\", all.x =TRUE)\n",
    "\n",
    "df <- df[ which(df$renewal_account_customers!=0), ]\n",
    "working_df <- df\n",
    "\n",
    "working_df$logged_over_300 <- log(df$over_300)\n",
    "working_df$logged_account_holders <- log(df$account_holders)\n",
    "working_df$logged_renewal_account_customers <- log(df$renewal_account_customers)\n",
    "working_df$first_of_month <- ifelse(substr(working_df$date, 9, 10) == '01', 1, 0)\n",
    "#working_df <- working_df[complete.cases(working_df),]\n",
    "\n",
    "library(forecast)\n",
    "churn_model <- Arima((working_df$dod_churn_rate), \n",
    "               order=c(0,0,1), \n",
    "               seasonal=c(0,0,0),\n",
    "               xreg=\n",
    "                 cbind(working_df$Wednesday, \n",
    "                       working_df$over_300,\n",
    "                       working_df$logged_renewal_account_customers,\n",
    "                       working_df$logged_account_holders, \n",
    "                       working_df$first_of_month),\n",
    "               lambda=0.1)\n",
    "\n",
    "# Create a vector of Wednesday values\n",
    "\n",
    "new_values <- as.data.frame(seq(from = 1, to = 365))\n",
    "\n",
    "new_values$Wednesday <- seq(Sys.Date(), to= Sys.Date()+364, by = \"day\")\n",
    "new_values$Wednesday <- weekdays(as.Date(new_values$Wednesday))\n",
    "new_values$Wednesday <- ifelse(new_values$Wednesday == \"Wednesday\", 1, 0)\n",
    "\n",
    "new_values$'seq(from = 1, to = 365)' <- NULL\n",
    "\n",
    "# Create a vector of over_300 values\n",
    "myvars <- c(\"date\", \"over_300\", \"logged_renewal_account_customers\",\n",
    "            \"logged_account_holders\")\n",
    "over_300_df <- working_df[myvars]\n",
    "\n",
    "# P6 has been in existance since August 1, 2014\n",
    "# P7a has been in existance since December 28th, 2015\n",
    "# P7b has been in existance since February 29th, 2016\n",
    "# P7c has been in existance since April 1st, 2016\n",
    "\n",
    "over_300_df$p6 <- ifelse(over_300_df$date <= '2015-12-28', 1, 0)\n",
    "over_300_df$p7a <- ifelse(over_300_df$date > '2015-12-28' & over_300_df$date <= '2016-02-29', 1, 0)\n",
    "over_300_df$p7b <- ifelse(over_300_df$date > '2016-02-29' & over_300_df$date <= '2016-04-01', 1, 0)\n",
    "over_300_df$p7c <- ifelse(over_300_df$date > '2016-04-01', 1, 0)\n",
    "\n",
    "dv1 <- ts(over_300_df$over_300, frequency=31)\n",
    "\n",
    "over_300_forecast <- auto.arima(dv1)\n",
    "x <- forecast(over_300_forecast, 365)\n",
    "new_values$over_300 <- x$mean\n",
    "\n",
    "# Create a vector of logged_renewal_account_customers values\n",
    "\n",
    "dv2 <- ts(over_300_df$logged_renewal_account_customers, frequency=31)\n",
    "\n",
    "renewal_model <- Arima(dv2, \n",
    "                       order=c(1,1,1), \n",
    "                       seasonal=c(1,0,0),\n",
    "                       xreg=\n",
    "                         cbind(over_300_df$p7b, \n",
    "                               over_300_df$p7c))\n",
    "\n",
    "new_values$p7b <- rep(0, 365) \n",
    "new_values$p7c <- rep(1, 365) \n",
    "\n",
    "logged_renewal_account_customers <- forecast(renewal_model, 365, xreg=\n",
    "                                               cbind(new_values$p7b, new_values$p7c))\n",
    "new_values$logged_renewal_account_customers <- logged_renewal_account_customers$mean\n",
    "\n",
    "# Create a vector of logged_account_holders values\n",
    "\n",
    "dv3 <- ts(over_300_df$logged_account_holders, frequency=31)\n",
    "\n",
    "account_model <- Arima(dv3, \n",
    "                       order=c(1,1,1), \n",
    "                       seasonal=c(1,0,0))\n",
    "\n",
    "logged_account_customers <- forecast(account_model, 365)\n",
    "new_values$logged_account_holders <- logged_account_customers$mean\n",
    "\n",
    "# Create a vector for first of the month\n",
    "\n",
    "new_values$date <- seq(Sys.Date(), to= Sys.Date()+364, by = \"day\")\n",
    "new_values$first_of_month <- ifelse(substr(new_values$date, 9, 10) == '01', 1, 0)\n",
    "\n",
    "results <- as.data.frame(forecast(churn_model, xreg=\n",
    "                                    cbind(new_values$Wednesday, \n",
    "                                          as.numeric(new_values$over_300),\n",
    "                                          new_values$logged_renewal_account_customers,\n",
    "                                          new_values$logged_account_holders, \n",
    "                                          new_values$first_of_month))\n",
    ")\n",
    "results$diff <- results[,5] - results[,1]\n",
    "\n",
    "\n",
    "results$date <- seq(Sys.Date(), to= Sys.Date()+364, by = \"day\")\n",
    "\n",
    "working_df$Wednesday <- ifelse(working_df$day == \"Wednesday\", 1, 0)\n",
    "\n",
    "original_forecast <- as.data.frame(forecast(churn_model, \n",
    "                                            xreg=\n",
    "                                              cbind(working_df$Wednesday,\n",
    "                                                    working_df$over_300,\n",
    "                                                    working_df$logged_renewal_account_customers,\n",
    "                                                    working_df$logged_account_holders,\n",
    "                                                    working_df$first_of_month)\n",
    "))\n",
    "\n",
    "original_forecast$date <- working_df$date\n",
    "\n",
    "myvars1 <- c(\"date\", \"dod_churn_rate\")\n",
    "recon_part1 <- working_df[myvars1]\n",
    "myvars2 <- c(\"date\", \"Point Forecast\")\n",
    "recon_part2 <- original_forecast[myvars2]\n",
    "\n",
    "reconciliation <-  merge(x = recon_part1, \n",
    "                         y = recon_part2, \n",
    "                         by.x = \"date\", by.y = \"date\", \n",
    "                         all.x = TRUE)\n",
    "\n",
    "reconciliation$diff <- reconciliation$dod_churn_rate - \n",
    "  reconciliation$'Point Forecast'\n",
    "mean_diff <- mean(reconciliation[[\"diff\"]], na.rm=TRUE)\n",
    "\n",
    "correctedforecast <- results\n",
    "correctedforecast$Adjusted_point <- results$'Point Forecast' + mean_diff\n",
    "correctedforecast$Adjusted_lo_80 <- results$'Lo 80' + mean_diff\n",
    "correctedforecast$Adjusted_hi_80 <- results$'Hi 80' + mean_diff\n",
    "correctedforecast$Adjusted_lo_95 <- results$'Lo 95' + mean_diff\n",
    "correctedforecast$Adjusted_hi_95 <- results$'Hi 95' + mean_diff\n",
    "correctedforecast$\"Point Forecast\" <- NULL\n",
    "correctedforecast$\"Lo 80\" <- NULL          \n",
    "correctedforecast$\"Hi 80\" <- NULL          \n",
    "correctedforecast$\"Lo 95\" <- NULL          \n",
    "correctedforecast$\"Hi 95\" <- NULL   \n",
    "\n",
    "rm(df, new_values, original_forecast, working_df,\n",
    "   over_300_df, pricing_plans, recon_part2,\n",
    "   recon_part1, account_model, con, drv, dv1,\n",
    "   dv2, dv3, logged_account_customers, \n",
    "   logged_renewal_account_customers, mean_diff,\n",
    "   churn_model, myvars, myvars1, myvars2, \n",
    "   over_300_forecast, query_1, renewal_model,\n",
    "   res_1, x, reconciliation)\n",
    "\n",
    "drv <- dbDriver('PostgreSQL')\n",
    "con <- dbConnect(drv, \n",
    "                 host=\"######################################\", \n",
    "                 port=\"########\",\n",
    "                 dbname=\"#######33\", \n",
    "                 user=\"########\", \n",
    "                 password=\"##################\")\n",
    "query_1 <- \"SELECT\n",
    "date,\n",
    "CASE WHEN date IN ('2016-02-26', '2016-02-27') THEN 0 ELSE new_new_plan END as new_new_plan,\n",
    "CASE WHEN date IN ('2016-02-26', '2016-02-27') THEN 0 ELSE new_new_module END as new_new_module,\n",
    "CASE WHEN date IN ('2016-02-26', '2016-02-27') THEN 0 ELSE new_new_variable END as new_new_variable,\n",
    "CASE WHEN date IN ('2016-02-26', '2016-02-27') THEN 0 ELSE new_upgrade_plan END as new_upgrade_plan,\n",
    "CASE WHEN date IN ('2016-02-26', '2016-02-27') THEN 0 ELSE new_upgrade_module END as new_upgrade_module,\n",
    "CASE WHEN date IN ('2016-02-26', '2016-02-27') THEN 0 ELSE new_upgrade_variable END as new_upgrade_variable\n",
    "FROM(\n",
    "SELECT \n",
    "date, \n",
    "COALESCE(CASE WHEN new_new_plan = first_new_new_plan THEN new_new_plan \n",
    "ELSE new_new_plan - LAG(new_new_plan) OVER (ORDER BY date) END, 0) AS new_new_plan,\n",
    "COALESCE(CASE WHEN new_new_module = first_new_new_module THEN new_new_module \n",
    "ELSE new_new_module - LAG(new_new_module) OVER (ORDER BY date) END , 0) AS new_new_module,\n",
    "COALESCE(CASE WHEN new_new_variable = first_new_new_variable THEN new_new_variable \n",
    "ELSE new_new_variable - LAG(new_new_variable) OVER (ORDER BY date) END , 0) AS new_new_variable,\n",
    "COALESCE(CASE WHEN new_upgrade_plan = first_new_upgrade_plan THEN new_upgrade_plan\n",
    "ELSE new_upgrade_plan - LAG(new_upgrade_plan) OVER (ORDER BY date) END , 0) AS new_upgrade_plan,\n",
    "COALESCE(CASE WHEN new_upgrade_module = first_new_upgrade_module THEN new_upgrade_module \n",
    "ELSE new_upgrade_module - LAG(new_upgrade_module) OVER (ORDER BY date) END , 0) AS new_upgrade_module,\n",
    "COALESCE(CASE WHEN new_upgrade_variable = first_new_upgrade_variable THEN new_upgrade_variable\n",
    "ELSE new_upgrade_variable - LAG(new_upgrade_variable) OVER (ORDER BY date) END , 0) AS \t\t\t\t  new_upgrade_variable\n",
    "FROM\n",
    "(\n",
    "  SELECT a.date, first_new_new_plan, new_new_plan, first_new_new_module, new_new_module,\n",
    "  first_new_new_variable, new_new_variable, first_new_upgrade_plan, new_upgrade_plan,\n",
    "  first_new_upgrade_module, new_upgrade_module, first_new_upgrade_variable, \n",
    "  new_upgrade_variable\n",
    "  FROM \n",
    "  (\n",
    "  SELECT *\n",
    "  FROM\n",
    "  (\n",
    "  SELECT \n",
    "  DATE(dateadd(day,730,(getdate()::date - row_number() over (order by true))::date)) as date\n",
    "  FROM data_warehouse.activity_account \n",
    "  )\n",
    "  WHERE date >= '2015-07-01'\n",
    "  AND date < CURRENT_DATE\n",
    "  ORDER BY date\n",
    "  ) a\n",
    "  LEFT JOIN\n",
    "  (\n",
    "  SELECT  \n",
    "  log_ymd as date, \n",
    "  first_value(new_new_plan) OVER (partition by to_char(log_ymd, 'YYYY-MM')) \n",
    "  AS first_new_new_plan,\n",
    "  new_new_plan,\n",
    "  first_value(new_new_module) OVER (partition by to_char(log_ymd, 'YYYY-MM')) \n",
    "  AS first_new_new_module,\n",
    "  new_new_module,\n",
    "  first_value(new_new_variable) OVER (partition by to_char(log_ymd, 'YYYY-MM')) \n",
    "  AS first_new_new_variable,\n",
    "  new_new_variable,\n",
    "  first_value(new_upgrade_plan) OVER (partition by to_char(log_ymd, 'YYYY-MM')) \n",
    "  AS first_new_upgrade_plan,\t\n",
    "  new_upgrade_plan,\n",
    "  first_value(new_upgrade_module) OVER (partition by to_char(log_ymd, 'YYYY-MM')) \n",
    "  AS first_new_upgrade_module,\n",
    "  new_upgrade_module,\n",
    "  first_value(new_upgrade_variable) OVER (partition by to_char(log_ymd, 'YYYY-MM')) \n",
    "  AS first_new_upgrade_variable,\n",
    "  new_upgrade_variable\n",
    "  FROM data_warehouse.account_financial_mrr_log\n",
    "  WHERE EXTRACT(month FROM cohort_year_month_date) = EXTRACT(month FROM log_ymd)\n",
    "  AND cohort_year_month_date <= DATE(convert_timezone('GMT','US/Pacific',CURRENT_DATE))\n",
    "  AND to_char(log_ymd, 'YYYY-MM') = cohort_year_month \n",
    "  AND cohort_type = 'all'\n",
    "  AND deleted_at IS NULL\n",
    "  ) b\n",
    "  ON a.date = b.date\n",
    ")\n",
    "WHERE date > '2015-11-16'\n",
    "ORDER BY date\n",
    ")\n",
    "ORDER BY date\"\n",
    "\n",
    "res_2 <- dbSendQuery(con, query_1, timeout = 600)\n",
    "df  <- as.data.frame(dbFetch(res_2)); dbClearResult(res_2)\n",
    "library(lubridate)\n",
    "df$months <- paste(year(df$date), '-', month(df$date),sep='')\n",
    "\n",
    "df$total_new_mrr  <- df$new_new_plan + df$new_new_module + df$new_new_variable    \n",
    "+ df$new_upgrade_plan + df$new_upgrade_module +df$new_upgrade_variable\n",
    "\n",
    "# Add Tuesdays\n",
    "\n",
    "df$day <- weekdays(as.Date(df$date))\n",
    "df$Tuesday <- ifelse(df$day == \"Tuesday\", 1, 0)\n",
    "\n",
    "# Add order data\n",
    "\n",
    "query_2 <- \"SELECT\n",
    "DATE(date_added) AS date_added_date, \n",
    "COUNT(DISTINCT o.id) AS number_of_orders, \n",
    "CASE WHEN DATE(date_added) > '2016-03-08' THEN 1 ELSE 0 END\n",
    "AS shard_glitch_start\n",
    "FROM data_warehouse.salesforce_transfer AS salesforce_transfer\n",
    "LEFT JOIN data_warehouse.order AS o ON (o.account_id) = salesforce_transfer.account_id\n",
    "WHERE (salesforce_transfer.ignore_data = 0) AND ((((o.date_added) >= ((DATEADD(month,-12, DATE_TRUNC('month', DATE_TRUNC('day',CONVERT_TIMEZONE('UTC', 'America/Los_Angeles', GETDATE()))) ))) AND (o.date_added) < ((DATEADD(month,13, DATEADD(month,-12, DATE_TRUNC('month', DATE_TRUNC('day',CONVERT_TIMEZONE('UTC', 'America/Los_Angeles', GETDATE()))) ) )))))) AND (o.deleted = 0) AND (o.historical_import = 0) AND (o.void = 0)\n",
    "GROUP BY 1\n",
    "ORDER BY 1 DESC\n",
    "\"\n",
    "res_3 <- dbSendQuery(con, query_2, timeout = 600)\n",
    "order_df  <- as.data.frame(dbFetch(res_3)); dbClearResult(res_3)\n",
    "order_df$date <- order_df$date_added\n",
    "order_df$date_added <- NULL\n",
    "\n",
    "df <- merge(x = df, y = order_df, by.x = \"date\",\n",
    "            by.y = \"date\", all.x = TRUE)\n",
    "\n",
    "# Add the Adwords data\n",
    "\n",
    "query_3 <- \"SELECT \n",
    "date,\n",
    "SUM(CASE WHEN campaign_id IN (195508785, 195508665, 195509025, 195508905, 121102665, 195508545) \n",
    "THEN cost ELSE 0 END) AS Brand,\n",
    "SUM(CASE WHEN campaign_id IN (195514905, 138943905, 195514665, 147887865, 195514545, 195515025, \n",
    "195514785, 158181225, 195608745, 179973825, 197051505, 195961665) \n",
    "THEN cost ELSE 0 END) AS Generic,\n",
    "SUM(CASE WHEN campaign_id IN (179781345) THEN cost ELSE 0 END) AS Remarketing,\n",
    "SUM(CASE WHEN campaign_id IN (196116465, 196116345) THEN cost ELSE 0 END) AS Competitor\n",
    "FROM\n",
    "adwords._campaign_performance_report\n",
    "GROUP BY date\n",
    "ORDER BY date\"\n",
    "\n",
    "#dbDisconnect(con)\n",
    "res_4 <- dbSendQuery(con, query_3, timeout = 600)\n",
    "adwords_df  <- as.data.frame(dbFetch(res_4)); dbClearResult(res_4)\n",
    "\n",
    "df <- merge(x = df, y = adwords_df, by.x = \"date\", by.y = \"date\", all.x = TRUE)\n",
    "\n",
    "# Create Lags\n",
    "library(dplyr)\n",
    "working_df  <- \n",
    "  df %>%  mutate(order_lag15 = lag(number_of_orders, 15)) \n",
    "working_df  <- \n",
    "  working_df %>%  mutate(brand_lag29 = lag(brand, 29)) \n",
    "\n",
    "\n",
    "# Create a forecast for brand spend. Brad estimates brand spend as varying from\n",
    "# 100% to 90% of its current rate\n",
    "library(zoo)\n",
    "rolling_mean <- (rollapply(zoo(df$brand), 30, mean, fill = NA))\n",
    "recent_mean <- rolling_mean[complete.cases(rolling_mean),]\n",
    "brand_spend <- recent_mean[length(recent_mean)] \n",
    "brand_spend <- as.data.frame(rep((brand_spend*.95), 365)) \n",
    "brand_spend$brand <- brand_spend[,1] \n",
    "brand_spend[,1] <- NULL\n",
    "rm(rolling_mean, recent_mean)\n",
    "\n",
    "# Create a forecast for the order input\n",
    "\n",
    "orders <- ts(order_df$number_of_orders, frequency=7)\n",
    "order_df$December <- ifelse(substr(order_df$date, 6, 7) == '12', 1, 0)\n",
    "\n",
    "order_model <- Arima(orders, \n",
    "                     order=c(4,1,1), \n",
    "                     seasonal=c(1,1,1),\n",
    "                     xreg=cbind(order_df$shard_glitch_star, order_df$December))\n",
    "\n",
    "# Create a vector of 1's for the shard glitch\n",
    "\n",
    "ones_vector <- as.data.frame(rep(1, 365)) \n",
    "ones_vector$glitch <- rep(1, 365)\n",
    "ones_vector$'rep(1, 365)' <- NULL\n",
    "december_vector <- as.data.frame(seq(Sys.Date(), to= Sys.Date()+364, by = \"day\"))\n",
    "december_vector$date <- december_vector$'seq(Sys.Date(), to = Sys.Date() + 364, by = \\\"day\\\"'\n",
    "december_vector[,1:1] <-NULL\n",
    "december_vector$Dec <- ifelse(substr(december_vector$date, 6, 7) == 12, 1, 0)\n",
    "\n",
    "order_model <- Arima(orders, \n",
    "                     order=c(4,1,1), \n",
    "                     seasonal=c(1,1,1),\n",
    "                     xreg=cbind(order_df$shard_glitch_star, order_df$December))\n",
    "\n",
    "library(forecast)\n",
    "order_forecast <- forecast(order_model, \n",
    "                           xreg = cbind(ones_vector$glitch,\n",
    "                                        december_vector$Dec))\n",
    "\n",
    "order_forecast <- as.data.frame(order_forecast$mean)\n",
    "order_forecast$date <- seq(Sys.Date(), to= Sys.Date()+364, by = \"day\")\n",
    "order_forecast$number_of_orders <- order_forecast$x\n",
    "order_forecast$x <- NULL\n",
    "myvars <- c(\"date\", \"number_of_orders\")\n",
    "original_orders <- df[myvars]\n",
    "order_forecast <- rbind(original_orders, order_forecast)\n",
    "order_forecast <- \n",
    "  order_forecast %>% mutate(order_forecast_lagged = lag(number_of_orders, 15))\n",
    "new_order_forecast <- order_forecast[ which(order_forecast$date > (Sys.Date()-1)), ]\n",
    "#new_order_forecast <- new_order_forecast[-1,]\n",
    "rm(december_vector, ones_vector, order_forecast, original_orders, order_df)\n",
    "\n",
    "# Create a vector of Tuesdays\n",
    "\n",
    "new_order_forecast$day <- weekdays(as.Date(new_order_forecast$date))\n",
    "new_order_forecast$Tuesday <- \n",
    "  ifelse(new_order_forecast$day == \"Tuesday\", 1, 0)\n",
    "\n",
    "# Apply regressors \n",
    "screening_df <- working_df[ which(working_df$date > '2015-12-17'), ]\n",
    "x <- ts(screening_df$total_new_mrr, frequency=31)\n",
    "\n",
    "model <- Arima(x, \n",
    "               order=c(0,1,1), \n",
    "               seasonal=c(0,1,1),\n",
    "               xreg=cbind(screening_df$brand_lag29,\n",
    "                          screening_df$order_lag15, \n",
    "                          screening_df$Tuesday))\n",
    "new_order_forecast <- new_order_forecast[-1,]\n",
    "forecast <- as.data.frame(forecast(model, xreg=\n",
    "                          cbind(brand_spend[1:nrow(new_order_forecast),],\n",
    "                          new_order_forecast$order_forecast_lagged, \n",
    "                          new_order_forecast$Tuesday)\n",
    "))\n",
    "forecast$date <- seq(Sys.Date(), to= Sys.Date()+(nrow(forecast)-1), by = \"day\")\n",
    "\n",
    "original_forecast <- as.data.frame(forecast(model, \n",
    "                                            xreg=\n",
    "                                              cbind(screening_df$brand_lag29,\n",
    "                                                    screening_df$order_lag15, \n",
    "                                                    screening_df$Tuesday)\n",
    "))\n",
    "original_forecast$date <- seq(as.Date('2015-12-18'), \n",
    "                              to=Sys.Date()-1, by = \"day\")\n",
    "\n",
    "myvars1 <- c(\"date\", \"total_new_mrr\")\n",
    "recon_part1 <- screening_df[myvars1]\n",
    "myvars2 <- c(\"date\", \"Point Forecast\")\n",
    "recon_part2 <- original_forecast[myvars2]\n",
    "\n",
    "reconciliation <-  merge(x = recon_part1, \n",
    "                         y = recon_part2, \n",
    "                         by.x = \"date\", by.y = \"date\", \n",
    "                         all.x = TRUE)\n",
    "\n",
    "rm(myvars1, myvars2, recon_part1, recon_part2)\n",
    "\n",
    "reconciliation$diff <- reconciliation$total_new_mrr - \n",
    "  reconciliation$'Point Forecast'\n",
    "mean_diff <- mean(reconciliation[[\"diff\"]], na.rm=TRUE)\n",
    "\n",
    "correctedrevenueforecast <- forecast\n",
    "correctedrevenueforecast$Adjusted_point <- forecast$'Point Forecast' + mean_diff\n",
    "correctedrevenueforecast$Adjusted_lo_80 <- forecast$'Lo 80' + mean_diff\n",
    "correctedrevenueforecast$Adjusted_hi_80 <- forecast$'Hi 80' + mean_diff\n",
    "correctedrevenueforecast$Adjusted_lo_95 <- forecast$'Lo 95' + mean_diff\n",
    "correctedrevenueforecast$Adjusted_hi_95 <- forecast$'Hi 95' + mean_diff\n",
    "correctedrevenueforecast$\"Point Forecast\" <- NULL\n",
    "correctedrevenueforecast$\"Lo 80\" <- NULL          \n",
    "correctedrevenueforecast$\"Hi 80\" <- NULL          \n",
    "correctedrevenueforecast$\"Lo 95\" <- NULL          \n",
    "correctedforecast$\"Hi 95\" <- NULL         \n",
    "\n",
    "rm(adwords_df, brand_spend, df, new_order_forecast,\n",
    "   screening_df, working_df, con, drv, model,\n",
    "   myvars, order_model, orders, query_1, query_2,\n",
    "   query_3, res_2, res_3, x, reconciliation,\n",
    "   original_forecast, mean_diff)\n",
    "\n",
    "df <- merge(x = correctedrevenueforecast, \n",
    "            y = correctedforecast, by.x = \"date\",\n",
    "            by.y = \"date\", all.x = TRUE)\n",
    "\n",
    "\n",
    "\n",
    "drv <- dbDriver('PostgreSQL')\n",
    "con <- dbConnect(drv, \n",
    "                 host=\"########################\", \n",
    "                 port=\"########\",\n",
    "                 dbname=\"######\", \n",
    "                 user=\"########\", \n",
    "                 password=\"############\")\n",
    "query_5 <- \"SELECT\n",
    "TO_CHAR(account_financial_mrr_log.cohort_year_month_date, 'YYYY-MM') AS cohort,\n",
    "DATE(account_financial_mrr_log.log_ymd) AS log_ymd,\n",
    "COALESCE(SUM(account_financial_mrr_log.arr), 0) AS arr\n",
    "FROM data_warehouse.account_financial_mrr_log AS account_financial_mrr_log\n",
    "WHERE (account_financial_mrr_log.deleted_at IS NULL) AND (account_financial_mrr_log.cohort_type = 'all') \n",
    "AND ((((account_financial_mrr_log.cohort_year_month_date) >= ((DATE_TRUNC('month', \n",
    "DATE_TRUNC('day',CONVERT_TIMEZONE('UTC', 'America/Los_Angeles', GETDATE()))))) \n",
    "AND (account_financial_mrr_log.cohort_year_month_date) < ((DATEADD(month,1, DATE_TRUNC('month', \n",
    "DATE_TRUNC('day',CONVERT_TIMEZONE('UTC', 'America/Los_Angeles', GETDATE()))) )))))) \n",
    "AND ((((account_financial_mrr_log.log_ymd) >= ((DATE_TRUNC('day',\n",
    "CONVERT_TIMEZONE('UTC', 'America/Los_Angeles', GETDATE())))) \n",
    "AND (account_financial_mrr_log.log_ymd) < ((DATEADD(day,1, DATE_TRUNC('day',CONVERT_TIMEZONE('UTC', \n",
    "'America/Los_Angeles', GETDATE())) ))))))\n",
    "GROUP BY 1,2\n",
    "ORDER BY 2 DESC\n",
    "LIMIT 500\"\n",
    "\n",
    "res_5 <- dbSendQuery(con, query_5, timeout = 600)\n",
    "current_arr  <- as.data.frame(dbFetch(res_5)); dbClearResult(res_5)\n",
    "arr <- current_arr[,3]\n",
    "rm(drv, con, query_5, res_4, current_arr)\n",
    "\n",
    "\n",
    "\n",
    "df <- df[1:90,]\n",
    "df$total_1 <- arr + df$Adjusted_point.x - \n",
    "             ((arr + df$Adjusted_point.x)*df$Adjusted_point.y)\n",
    "\n",
    "library(magic)\n",
    "df$total_2 <- df$Adjusted_point.x + \n",
    "              shift(df$total_1, 1L) -\n",
    "              ((df$Adjusted_point.x + \n",
    "              shift(df$total_1, 1L))*\n",
    "              df$Adjusted_point.y)\n",
    "\n",
    "df$Final_Pred <- df$total_2\n",
    "\n",
    "myvars <- c(\"date\", \"Final_Pred\")\n",
    "final_df <- df[myvars]\n",
    "\n",
    "rm(res_5, arr, forecast, correctedrevenueforecast, correctedforecast,\n",
    "   results, df, myvars)\n",
    "\n",
    "final_df$Final_Pred <- ts(final_df$Final_Pred)\n",
    "head(final_df, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   point_forecast   lo_80   hi_80   lo_95   hi_95 forecasted_for forecasted_on\n",
       "85        6321855 6320119 6322467 6319491 6323125     2016-09-16    2016-06-24\n",
       "86        6322606 6320104 6322448 6319502 6323095     2016-09-17    2016-06-24\n",
       "87        6322651 6320099 6322465 6319465 6323084     2016-09-18    2016-06-24\n",
       "88        6322047 6320122 6322472 6319490 6323107     2016-09-19    2016-06-24\n",
       "89        6322018 6320128 6322479 6319497 6323091     2016-09-20    2016-06-24\n",
       "90        6321645 6320134 6322484 6319510 6323112     2016-09-21    2016-06-24\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R \n",
    "# Documentation for bootstrapping is here:\n",
    "# http://www.inside-r.org/packages/cran/FitAR/docs/Boot.ts\n",
    "# Another reference of interest is here:\n",
    "# http://eranraviv.com/bootstrapping-time-series-r-code/\n",
    "# library(zoo)\n",
    "# final_df$Filled_Pred <- na.locf(final_df$Final_Pred, na.rm = TRUE)\n",
    "ts<- ts(final_df$Final_Pred)\n",
    "colnames(final_df)[colnames(final_df)==\"Final_Pred\"] <- \"point_forecast\"\n",
    "\n",
    "library(FitAR)\n",
    "boot_matrix <- as.matrix(Boot(ts, R=10000))\n",
    "final_df$lo_80 <- apply(boot_matrix, 1, quantile, \n",
    "                        probs = c(0.1),  na.rm = TRUE)\n",
    "final_df$hi_80 <- apply(boot_matrix, 1, quantile, \n",
    "                  probs = c(0.9),  na.rm = TRUE)\n",
    "final_df$lo_95 <- apply(boot_matrix, 1, quantile, \n",
    "                        probs = c(0.025),  na.rm = TRUE)\n",
    "final_df$hi_95 <- apply(boot_matrix, 1, quantile, \n",
    "                        probs = c(0.975),  na.rm = TRUE)\n",
    "final_df$forecasted_on <- Sys.Date()\n",
    "output_df <- final_df\n",
    "output_df$forecasted_for <- output_df$date\n",
    "output_df$date <- NULL\n",
    "output_df$Final_Pred <- NULL\n",
    "output_df <- output_df[c(1,2,3,4,5,7,6)]\n",
    "tail(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  point_forecast    lo_80    hi_80    lo_95    hi_95 forecasted_for\n",
       "1       526733.7 526675.3 526873.1 526624.5 526923.9     2016-06-24\n",
       "2       526644.0 526678.2 526872.6 526626.3 526922.8     2016-06-25\n",
       "3       526650.7 526676.2 526871.1 526625.2 526922.8     2016-06-26\n",
       "4       526704.7 526677.8 526871.9 526624.2 526922.8     2016-06-27\n",
       "5       526673.1 526679.9 526876.5 526626.6 526927.5     2016-06-28\n",
       "6       526612.4 526678.2 526871.8 526626.1 526928.0     2016-06-29\n",
       "  forecasted_on\n",
       "1    2016-06-24\n",
       "2    2016-06-24\n",
       "3    2016-06-24\n",
       "4    2016-06-24\n",
       "5    2016-06-24\n",
       "6    2016-06-24\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R \n",
    "# Rescale to MRR\n",
    "output_df[,1] <- output_df[,1]/12\n",
    "output_df[,2] <- output_df[,2]/12\n",
    "output_df[,3] <- output_df[,3]/12\n",
    "output_df[,4] <- output_df[,4]/12\n",
    "output_df[,5] <- output_df[,5]/12\n",
    "head(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%R -o output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_df.forecasted_on = (output_df.forecasted_on.astype(int)+719163).apply(dt.date.fromordinal)\n",
    "output_df.forecasted_for = (output_df.forecasted_for.astype(int)+719163).apply(dt.date.fromordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>point_forecast</th>\n",
       "      <th>lo_80</th>\n",
       "      <th>hi_80</th>\n",
       "      <th>lo_95</th>\n",
       "      <th>hi_95</th>\n",
       "      <th>forecasted_for</th>\n",
       "      <th>forecasted_on</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>526733.746460</td>\n",
       "      <td>526675.317879</td>\n",
       "      <td>526873.079039</td>\n",
       "      <td>526624.496621</td>\n",
       "      <td>526923.902115</td>\n",
       "      <td>2016-06-24</td>\n",
       "      <td>2016-06-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>526644.014231</td>\n",
       "      <td>526678.204909</td>\n",
       "      <td>526872.554032</td>\n",
       "      <td>526626.272619</td>\n",
       "      <td>526922.781798</td>\n",
       "      <td>2016-06-25</td>\n",
       "      <td>2016-06-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>526650.719834</td>\n",
       "      <td>526676.232554</td>\n",
       "      <td>526871.137118</td>\n",
       "      <td>526625.194378</td>\n",
       "      <td>526922.845460</td>\n",
       "      <td>2016-06-26</td>\n",
       "      <td>2016-06-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>526704.692354</td>\n",
       "      <td>526677.821160</td>\n",
       "      <td>526871.906203</td>\n",
       "      <td>526624.229753</td>\n",
       "      <td>526922.827781</td>\n",
       "      <td>2016-06-27</td>\n",
       "      <td>2016-06-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>526673.117098</td>\n",
       "      <td>526679.853922</td>\n",
       "      <td>526876.483541</td>\n",
       "      <td>526626.621147</td>\n",
       "      <td>526927.475126</td>\n",
       "      <td>2016-06-28</td>\n",
       "      <td>2016-06-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   point_forecast          lo_80          hi_80          lo_95          hi_95  \\\n",
       "1   526733.746460  526675.317879  526873.079039  526624.496621  526923.902115   \n",
       "2   526644.014231  526678.204909  526872.554032  526626.272619  526922.781798   \n",
       "3   526650.719834  526676.232554  526871.137118  526625.194378  526922.845460   \n",
       "4   526704.692354  526677.821160  526871.906203  526624.229753  526922.827781   \n",
       "5   526673.117098  526679.853922  526876.483541  526626.621147  526927.475126   \n",
       "\n",
       "  forecasted_for forecasted_on  \n",
       "1     2016-06-24    2016-06-24  \n",
       "2     2016-06-25    2016-06-24  \n",
       "3     2016-06-26    2016-06-24  \n",
       "4     2016-06-27    2016-06-24  \n",
       "5     2016-06-28    2016-06-24  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output_df.to_csv('output_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# output_df = pd.read_csv('output_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# output_df.drop(['Unnamed: 0'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reload(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from stitch.query import Redshift as rs\n",
    "def insert_mrr_predictions():\n",
    "    schema='data_team'\n",
    "    tablename='mrr_forecast'\n",
    "    service='csv_import'\n",
    "    \n",
    "    #/*output_df*/\n",
    "    with rs.RedshiftConnection(user='fivetran',password='##########################33') as insert_conn:\n",
    "        insert_conn.jobAuditor.start(schema=schema,table=tablename,service=service,status='ok')\n",
    "        insert_conn.jobAuditor.log('initialize',True)\n",
    "        insert_conn.jobAuditor.log('max_record_at',dt.datetime.today())\n",
    "        #initialize = True - > truncates table and then inserts - start with a fresh table\n",
    "        #initialize = False - > appends\n",
    "        insert_conn.insert(schema,tablename,output_df,log=True,initialize=False,vacuum=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "insert_mrr_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}