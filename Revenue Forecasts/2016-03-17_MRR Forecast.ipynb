{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary Python packages - particularly rpy2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from rpy2.robjects.packages import importr # You may need to run \"pip install rpy2\" in Terminal\n",
    "import rpy2 as ro\n",
    "import pandas as pd\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benjamins-air.sf.stch.co\n"
     ]
    }
   ],
   "source": [
    "from stitch.query import Redshift as rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0919d1980c9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m with rs.RedshiftConnection(\n\u001b[0m\u001b[1;32m      2\u001b[0m     user='########',password='#################') as conn:\n\u001b[1;32m      3\u001b[0m     \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"set search_path = 'data_warehouse';\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     query1=\"\"\"\n\u001b[1;32m      5\u001b[0m         \u001b[0mSELECT\u001b[0m \u001b[0mDISTINCT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rs' is not defined"
     ]
    }
   ],
   "source": [
    "with rs.RedshiftConnection(\n",
    "    user='############',password='#################') as conn:\n",
    "    conn.execute(\"set search_path = 'data_warehouse';\")\n",
    "    query1=\"\"\"\n",
    "        SELECT DISTINCT(a.ts) as ts, (arr/12) as mrr\n",
    "        FROM\n",
    "        (\n",
    "            SELECT DISTINCT DATE(created_at) as ts\n",
    "            FROM activity_account\n",
    "        ) a\n",
    "        LEFT  JOIN\n",
    "        (\n",
    "            SELECT log_ymd as ts, arr, deleted_at\n",
    "            FROM account_financial_mrr_log\n",
    "            WHERE EXTRACT(month FROM cohort_year_month_date) = EXTRACT(month FROM log_ymd)\n",
    "            AND cohort_year_month_date >= '2015-08-01' \n",
    "            AND cohort_year_month_date <= DATE(convert_timezone('GMT','US/Pacific',CURRENT_DATE))\n",
    "        ) b\n",
    "        ON a.ts = b.ts\n",
    "        WHERE a.ts >= '2015-08-01'\n",
    "        AND deleted_at IS NULL\n",
    "        ORDER BY ts\n",
    "    \"\"\"\n",
    "    df = conn.query(query1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R -i df\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%R plot(df$mrr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With outliers removed, we have 72 missing observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R \n",
    "df$mrr[df$mrr < 200000] <- NA\n",
    "df$mrr[df$mrr > 510110.7] <- NA\n",
    "sum(is.na(df$mrr)) # ... and count missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R -o df # Export the R object \"df\" into python...\n",
    "#install.packages('imputeTS', repos='http://cran.us.r-project.org')\n",
    "library('imputeTS')\n",
    "ts <- ts(df$mrr)\n",
    "df$mrr <- na.interpolation(ts, option =\"spline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After interpolating the missing data, we can use the \"tseries\" package from CRAN to test for stationarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R -i df # Import the Python object \"df\" into R...\n",
    "#Check the stationary assumption\n",
    "#install.packages('tseries', repos='http://cran.us.r-project.org')\n",
    "library('tseries')\n",
    "test <- ts(df$mrr)\n",
    "adf.test(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R -i df # Import the Python object \"df\" into R...\n",
    "# Take the first differences\n",
    "df_diff <- diff(df$mrr,1)\n",
    "plot(df_diff, type='l')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R -i df # Import the Python object \"df\" into R...\n",
    "#install.packages('astsa', repos='http://cran.us.r-project.org')\n",
    "library(astsa)\n",
    "acf2(df_diff, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The package necessary for constructing a periodgram can be found in the \"TSA\" package from CRAN.\n",
    "See: https://cran.r-project.org/web/packages/TSA/TSA.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from rpy2.robjects.packages import importr\n",
    "# utils = importr('utils')\n",
    "# utils.install_packages('TSA')\n",
    "# r.packages.utils.install_packages(package_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A periodogram of the data concurs with the ACF and PACF and confirms the absence of seasonlity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R # Import the Python object \"df\" into R...\n",
    "# install.packages('TSA', repos='http://cran.us.r-project.org')\n",
    "library('TSA')\n",
    "test <- ts(df$mrr)\n",
    "periodogram(test,ylab='Variable Star Periodogram');  abline(h=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R -i df # Import the Python object \"df\" into R...\n",
    "#install.packages('forecast', repos='http://cran.us.r-project.org')\n",
    "library(forecast)\n",
    "# compel the auto.arima to assume no seasonality, 7-day seasonality, and 30-day seasonality\n",
    "ts_0 <- ts(df$mrr) \n",
    "# ts_1 <- ts(df$mrr,frequency=7) \n",
    "# ts_2 <- ts(df$mrr,frequency=30) \n",
    "fit0 <- auto.arima(ts_0, trace=TRUE, allowdrift=FALSE, ic=\"aicc\", seasonal=TRUE, lambda=0) \n",
    "# fit1 <- auto.arima(ts_1, trace=TRUE, allowdrift=TRUE, ic=\"bic\", seasonal=TRUE, lambda=0) \n",
    "# fit2 <- auto.arima(ts_2, trace=TRUE, allowdrift=TRUE, ic=\"bic\", seasonal=TRUE, lambda=0)\n",
    "# # other ic options are \"aicc\" and \"bic\"\n",
    "# fit0\n",
    "# fit1\n",
    "# fit2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R -i df # Import the Python object \"df\" into R...\n",
    "# http://artax.karlin.mff.cuni.cz/r-help/library/TSA/html/tsdiag.Arima.html\n",
    "# model1 <- Arima(df$mrr, order=c(1,1,2),lambda=0, seasonal = list(order = c(0, 0, 0), period = 0))\n",
    "# model1 <- Arima(df$mrr, order=c(1,1,2),lambda=0)\n",
    "# model1\n",
    "# model2 <- Arima(df$mrr, order=c(1,1,1),lambda=0)\n",
    "# model2\n",
    "model3 <- Arima(df$mrr, order=c(2,1,1),lambda=0)\n",
    "model3\n",
    "# model4 <- Arima(df$mrr, order=c(0,1,0),lambda=0)\n",
    "# model4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "png(filename=\"Forecast_Diagnostics.png\")\n",
    "tsdiag(model3, tol = 0.1, omit.initial = TRUE, col = \"red\")\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R -i df # Import the Python object \"df\" into R...\n",
    "# install.packages('lubridate', repos='http://cran.us.r-project.org')\n",
    "require(lubridate)\n",
    "days_until_ye <- (365 - yday(as.Date(Sys.Date())))\n",
    "days_until_ye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R -i df # Import the Python object \"df\" into R...\n",
    "# install.packages('forecast', repos='http://cran.us.r-project.org')\n",
    "# https://cran.r-project.org/web/packages/forecast/forecast.pdf\n",
    "library('forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "png(filename=\"MRR_Forecast.png\")\n",
    "mar.default <- c(5,4,4,2) + 0.1\n",
    "par(mar = mar.default + c(0, 4, 0, 0)) \n",
    "plot(forecast(model3, h=120), main=\"Projected MRR (60 Days Out)\", xlab=\"Month\", yaxt='n', xaxt='n') \n",
    "abline(v = 31, col = \"grey\") # August 1st, 2015\n",
    "abline(v = 63, col = \"grey\") # September 1st, 2015\n",
    "abline(v = 92, col = \"grey\") # October 1st, 2015\n",
    "abline(v = 123, col = \"grey\") # November 1st, 2015\n",
    "abline(v = 153, col = \"grey\") # December 1st, 2015\n",
    "abline(v = 184, col = \"grey\") # January 1st, 2016\n",
    "abline(v = 215, col = \"grey\") # February 1st, 2016\n",
    "abline(v = 244, col = \"grey\") # March 1st, 2016\n",
    "abline(v = 275, col = \"grey\") # April 1st, 2016\n",
    "abline(v = 305, col = \"grey\") # May 1st, 2016\n",
    "abline(v = (yday(as.Date(Sys.Date())) + 184), col = \"black\", lwd=2) # May 1st, 2016\n",
    "abline(h = 470496.54, col = \"red\", lty=2) # January 2016 MRR Target\n",
    "abline(h = 511009.73, col = \"red\", lty=2) # February 2016 MRR Target\n",
    "abline(h = 551163.49, col = \"red\", lty=2) # March 2016 MRR Target\n",
    "axis(2, at=axTicks(2), labels=sprintf(\"$%s\", axTicks(2)), las=1)\n",
    "axis(1, at = c(0,63,123,184,244,305), \n",
    "        labels = c(\"07/01/15\",\"09/01/15\",\"11/01/15\",\"01/01/16\",\"03/01/16\",\"05/01/16\"), \n",
    "        las=1)\n",
    "# legend(0,585000, c('Point Estimates','80% C.I.','95% C.I.'), lty=c(1,1), \n",
    "#        lwd=c(2.5,2.5),col=c('navy', 'slategray',\"slategray2\")) \n",
    "text(50, 480000, \"January Target\")\n",
    "text(125, 520000, \"February Target\")\n",
    "text(185, 560000, \"March Target\")\n",
    "# the \"las\" option specifies the axis label orientation, i.e. (0=parallel, 1=all horizontal, \n",
    "# 2=all perpendicular to axis, 3=all vertical)\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "output_df <- as.data.frame(forecast(model3, h=90))\n",
    "output_df$forecasted_for <- seq(as.Date(\"2016-03-18\"), as.Date(\"2016-06-15\",), by = \"days\") + 719163\n",
    "output_df$forecasted_on <- as.Date(\"2016-03-17\") +719163\n",
    "library(plyr)\n",
    "output_df <- rename(output_df, c(\"Point Forecast\" = \"point_forecast\"))\n",
    "output_df <- rename(output_df, c(\"Lo 80\" = \"lo_80\", \"Hi 80\" = \"hi_80\"))\n",
    "output_df <- rename(output_df, c(\"Lo 95\" = \"lo_95\", \"Hi 95\" = \"hi_95\"))\n",
    "as.numeric(output_df$forecasted_on)\n",
    "\n",
    "as.Date(\"1969-01-01\") - as.Date(\"0000-01-01\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%R -o output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_df.forecasted_for = output_df.forecasted_for.astype(int)\n",
    "output_df.forecasted_on = output_df.forecasted_on.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_df.forecasted_on = output_df.forecasted_on.apply(dt.date.fromordinal)\n",
    "output_df.forecasted_for = output_df.forecasted_for.apply(dt.date.fromordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output_df.to_csv('output_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# output_df = pd.read_csv('output_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# output_df.drop(['Unnamed: 0'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reload(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def insert_mrr_predictions():\n",
    "    schema='data_team'\n",
    "    tablename='mrr_forecast'\n",
    "    service='csv_import'\n",
    "    \n",
    "    #/*output_df*/\n",
    "    with rs.RedshiftConnection(user='###########',password='######################') as insert_conn:\n",
    "        insert_conn.jobAuditor.start(schema=schema,table=tablename,service=service,status='ok')\n",
    "        insert_conn.jobAuditor.log('initialize',True)\n",
    "        insert_conn.jobAuditor.log('max_record_at',dt.datetime.today())\n",
    "        #initialize = True - > truncates table and then inserts - start with a fresh table\n",
    "        #initialize = False - > appends\n",
    "        insert_conn.insert(schema,tablename,output_df,log=True,initialize=False,vacuum=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "insert_mrr_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}